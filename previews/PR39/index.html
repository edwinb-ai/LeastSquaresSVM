<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · LeastSquaresSVM</title><link rel="canonical" href="https://edwinb-ai.github.io/LeastSquaresSVM/stable/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">LeastSquaresSVM</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Formulation"><span>Formulation</span></a></li><li class="toplevel"><a class="tocitem" href="#Rationale"><span>Rationale</span></a></li><li><a class="tocitem" href="#Advantages"><span>Advantages</span></a></li><li><a class="tocitem" href="#Disadvantages"><span>Disadvantages</span></a></li><li class="toplevel"><a class="tocitem" href="#Bibliography"><span>Bibliography</span></a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="example1/">Classification of the Wisconsin breast cancer dataset</a></li><li><a class="tocitem" href="example2/">Regression on a synthetic dataset</a></li><li><a class="tocitem" href="example3/">Using different kernels</a></li><li><a class="tocitem" href="example4/">Multiclass classification</a></li></ul></li><li><a class="tocitem" href="reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/edwinb-ai/LeastSquaresSVM/blob/master/docs/src/index.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="LeastSquaresSVM"><a class="docs-heading-anchor" href="#LeastSquaresSVM">LeastSquaresSVM</a><a id="LeastSquaresSVM-1"></a><a class="docs-heading-anchor-permalink" href="#LeastSquaresSVM" title="Permalink"></a></h1><p>This is <code>LeastSquaresSVM</code>, a Least Squares Support Vector Machine (LSSVM) implementation in pure Julia. It is meant to be used together with the fantastic <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">MLJ.jl</a> Machine Learning framework.</p><h1 id="Formulation"><a class="docs-heading-anchor" href="#Formulation">Formulation</a><a id="Formulation-1"></a><a class="docs-heading-anchor-permalink" href="#Formulation" title="Permalink"></a></h1><p>It is a re-formulation of the classical Support Vector Machine (SVM) formalism. In this case we attempt to solve a least squares problem which is faster<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>, instead of the classic quadratic, convex optimization problem that is solved in the original Support Vector Machine.</p><p>In the case of <code>LeastSquaresSVM</code> we use the conjugate gradient method, in particular the Lanczos version<sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup> due to the fact that we solve several linear systems which have the the following structure</p><p class="math-container">\[A \mathbf{x} = \mathbf{b}\]</p><p>where the matrix <span>$A$</span> is symmetric.</p><p>This fact makes it a great candidate for the Lanczos algorithm, a very fast, iterative procedure based on Krylov subspace methods. The implementation used here is that from the <a href="https://juliasmoothoptimizers.github.io/Krylov.jl/dev/">Krylov.jl</a> package.</p><h1 id="Rationale"><a class="docs-heading-anchor" href="#Rationale">Rationale</a><a id="Rationale-1"></a><a class="docs-heading-anchor-permalink" href="#Rationale" title="Permalink"></a></h1><p>SVM has been the most known and used formulation, but here are some pros and cons for using LSSVMs and <code>LeastSquaresSVM</code>.</p><h2 id="Advantages"><a class="docs-heading-anchor" href="#Advantages">Advantages</a><a id="Advantages-1"></a><a class="docs-heading-anchor-permalink" href="#Advantages" title="Permalink"></a></h2><p>The LSSVM is a great alternative to the classic SVM in the following things:</p><ul><li>Solving a linear system is much easier and faster than solving a quadratic optimization problem.</li><li>Some useful properties from numerical linear algebra can be exploited in order to solve the new optimization problem.</li><li>One can potentialy train of thousands or millions of instances using LSSVM, something that the classic SVM cannot do. This is possible using the <em>fixed size LSSVM</em><sup class="footnote-reference"><a id="citeref-3" href="#footnote-3">[3]</a></sup>.</li><li>Less hyperparemeters to tune. LSSVM only has one intrinsic hyperparamter, whereas the SVM has at least two. This is without taking into account the kernel&#39;s hyperparameter.</li></ul><h2 id="Disadvantages"><a class="docs-heading-anchor" href="#Disadvantages">Disadvantages</a><a id="Disadvantages-1"></a><a class="docs-heading-anchor-permalink" href="#Disadvantages" title="Permalink"></a></h2><p>But there are some important <strong>shortcommings</strong> for the LSSVM, namely:</p><ul><li>In contrast with the classic SVM, the decision function lack all <em>sparseness.</em> Every single dataset instance must be used to train the LSSVM. This can become troublesome for very large problems because all the instances must fit into memory.</li><li>There is complete lack of interpretation for the <em>support vectors,</em> which are the data instances that are used to construct the decision function. Because all data instances are used, every instance is effectively a support vector and this removes any interpretation for the importance of each instance on the model&#39;s performance.</li></ul><h1 id="Bibliography"><a class="docs-heading-anchor" href="#Bibliography">Bibliography</a><a id="Bibliography-1"></a><a class="docs-heading-anchor-permalink" href="#Bibliography" title="Permalink"></a></h1><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Suykens, J. A., &amp; Vandewalle, J. (1999). Least squares support vector machine classifiers. Neural processing letters, 9(3), 293-300.</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>Fasano, G. (2007). Lanczos conjugate-gradient method and pseudoinverse computation on indefinite and singular systems. Journal of optimization theory and applications, 132(2), 267-285.</li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a>Espinoza, M., Suykens, J. A., &amp; De Moor, B. (2006). Fixed-size least squares support vector machines: A large scale application in electrical load forecasting. Computational Management Science, 3(2), 113-129.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="example1/">Classification of the Wisconsin breast cancer dataset »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 23 July 2021 22:18">Friday 23 July 2021</span>. Using Julia version 1.6.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
