<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Classification of the Wisconsin breast cancer dataset Â· LeastSquaresSVM</title><link rel="canonical" href="https://edwinb-ai.github.io/LeastSquaresSVM/stable/example1/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">LeastSquaresSVM</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Examples</span><ul><li class="is-active"><a class="tocitem" href>Classification of the Wisconsin breast cancer dataset</a></li><li><a class="tocitem" href="../example2/">Regression on a synthetic dataset</a></li><li><a class="tocitem" href="../example3/">Using different kernels</a></li><li><a class="tocitem" href="../example4/">Multiclass classification</a></li></ul></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Classification of the Wisconsin breast cancer dataset</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Classification of the Wisconsin breast cancer dataset</a></li></ul></nav><div class="docs-right"><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Classification-of-the-Wisconsin-breast-cancer-dataset"><a class="docs-heading-anchor" href="#Classification-of-the-Wisconsin-breast-cancer-dataset">Classification of the Wisconsin breast cancer dataset</a><a id="Classification-of-the-Wisconsin-breast-cancer-dataset-1"></a><a class="docs-heading-anchor-permalink" href="#Classification-of-the-Wisconsin-breast-cancer-dataset" title="Permalink"></a></h1><p>In this case study we will deal with the Wisconsin breast cancer dataset which can be browsed freely on the <a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)">UCI website</a>.</p><p>In particular, this dataset contains <em>10 features</em> and 699 instances. In the work we will do here, however, we will skip some instances due to some missing values.</p><p>The dataset contains only two classes, and the purpose is to use all ten features to answer a simple question:</p><blockquote><p>Does the subject have a benign or malign tumor?</p></blockquote><p>To answer this question, we will train a Least Squares Support Vector Machine as implemented in <code>LeastSquaresSVM</code>.</p><p>First, we need to import all the necessary packages.</p><pre><code class="language-julia">using MLJ, MLJBase
using DataFrames, CSV
using CategoricalArrays
using Random, Statistics
using LeastSquaresSVM</code></pre><p>We then need to specify a seed to enable reproducibility of the results.</p><pre><code class="language-julia">rng = MersenneTwister(801239);
</code></pre><p>Here we are creating a list with all the headers.</p><pre><code class="language-julia">headers = [
	&quot;id&quot;, &quot;Clump Thickness&quot;,
	&quot;Uniformity of Cell Size&quot;, &quot;Uniformity of Cell Shape&quot;,
	&quot;Marginal Adhesion&quot;, &quot;Single Epithelial Cell Size&quot;,
	&quot;Bare Nuclei&quot;, &quot;Bland Chromatin&quot;,
	&quot;Normal Nucleoli&quot;, &quot;Mitoses&quot;, &quot;class&quot;
];
</code></pre><p>We define the path were the dataset is located</p><pre><code class="language-julia">path = joinpath(&quot;src&quot;, &quot;examples&quot;, &quot;wbc.csv&quot;);
</code></pre><p>We load the csv file and convert it to a <code>DataFrame</code>. Note that we are specifying to the file reader to replace the string <code>?</code> to a <code>missing</code> value. This dataset contains the the string <code>?</code> when there is a value missing.</p><pre><code class="language-julia">data = CSV.File(path; header=headers, missingstring=&quot;?&quot;) |&gt; DataFrame;
</code></pre><p>We can display the first 10 rows from the dataset</p><pre><code class="language-julia">first(data, 10)</code></pre><pre><code class="language-none">10Ã—11 DataFrame
 Row â”‚ id       Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  class
     â”‚ Int64    Int64            Int64                    Int64                     Int64              Int64                        Int64?       Int64            Int64            Int64    Int64
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚ 1000025                5                        1                         1                  1                            2            1                3                1        1      2
   2 â”‚ 1002945                5                        4                         4                  5                            7           10                3                2        1      2
   3 â”‚ 1015425                3                        1                         1                  1                            2            2                3                1        1      2
   4 â”‚ 1016277                6                        8                         8                  1                            3            4                3                7        1      2
   5 â”‚ 1017023                4                        1                         1                  3                            2            1                3                1        1      2
   6 â”‚ 1017122                8                       10                        10                  8                            7           10                9                7        1      4
   7 â”‚ 1018099                1                        1                         1                  1                            2           10                3                1        1      2
   8 â”‚ 1018561                2                        1                         2                  1                            2            1                3                1        1      2
   9 â”‚ 1033078                2                        1                         1                  1                            2            1                1                1        5      2
  10 â”‚ 1033078                4                        2                         1                  1                            2            1                2                1        1      2</code></pre><p>We can see that all the features have been added correctly, we can see that we have an unncessary feature called <code>id</code>, so we will remove it.</p><pre><code class="language-julia">select!(data, Not(:id));
</code></pre><p>We also need to remove all the missing data from the <code>DataFrame</code></p><pre><code class="language-julia">data = dropmissing(data);
</code></pre><p>The <code>class</code> column should be of type <code>categorical</code>, following the <code>MLJ</code> API, so we encode it here.</p><pre><code class="language-julia">transform!(data, :class =&gt; categorical, renamecols=false);
</code></pre><p>Check statistics per column.</p><pre><code class="language-julia">describe(data)</code></pre><pre><code class="language-none">10Ã—7 DataFrame
 Row â”‚ variable                     mean     min  median  max  nmissing  eltype
     â”‚ Symbol                       Unionâ€¦   Any  Unionâ€¦  Any  Int64     DataType
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚ Clump Thickness              4.44217  1    4.0     10          0  Int64
   2 â”‚ Uniformity of Cell Size      3.15081  1    1.0     10          0  Int64
   3 â”‚ Uniformity of Cell Shape     3.21523  1    1.0     10          0  Int64
   4 â”‚ Marginal Adhesion            2.83016  1    1.0     10          0  Int64
   5 â”‚ Single Epithelial Cell Size  3.23426  1    2.0     10          0  Int64
   6 â”‚ Bare Nuclei                  3.54466  1    1.0     10          0  Int64
   7 â”‚ Bland Chromatin              3.4451   1    3.0     10          0  Int64
   8 â”‚ Normal Nucleoli              2.86969  1    1.0     10          0  Int64
   9 â”‚ Mitoses                      1.60322  1    1.0     10          0  Int64
  10 â”‚ class                                 2            4           0  CategoricalValue{Int64,UInt32}</code></pre><p>Split the dataset into training and testing.</p><pre><code class="language-julia">y, X = unpack(data, ==(:class), colname -&gt; true);
</code></pre><p>We will use only 2/3 for training.</p><pre><code class="language-julia">train, test = partition(eachindex(y), 2 / 3, shuffle=true, rng=rng);
</code></pre><p>Always remove mean and set the standard deviation to 1.0 when dealing with SVMs.</p><pre><code class="language-julia">stand1 = Standardizer(count=true);
X = MLJBase.transform(fit!(machine(stand1, X)), X);
</code></pre><pre><code class="language-none">â”Œ Info: Training [34mMachine{Standardizer} @008[39m.
â”” @ MLJBase /home/edwin/.julia/packages/MLJBase/5TNcr/src/machines.jl:319
</code></pre><p>Check statistics per column again to ensure standardization, but remember to do it now with the <code>X</code> matrix.</p><pre><code class="language-julia">describe(X)</code></pre><pre><code class="language-none">9Ã—7 DataFrame
 Row â”‚ variable                     mean          min        median     max      nmissing  eltype
     â”‚ Symbol                       Float64       Float64    Float64    Float64  Int64     DataType
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1 â”‚ Clump Thickness               6.90029e-17  -1.2203    -0.156754  1.97033         0  Float64
   2 â”‚ Uniformity of Cell Size      -3.5111e-17   -0.701698  -0.701698  2.23454         0  Float64
   3 â”‚ Uniformity of Cell Shape     -7.44483e-17  -0.74123   -0.74123   2.27023         0  Float64
   4 â”‚ Marginal Adhesion             9.96437e-17  -0.638897  -0.638897  2.50294         0  Float64
   5 â”‚ Single Epithelial Cell Size  -5.29103e-17  -1.00503   -0.555202  3.0434          0  Float64
   6 â”‚ Bare Nuclei                  -2.77962e-17  -0.698341  -0.698341  1.77157         0  Float64
   7 â”‚ Bland Chromatin               6.11192e-17  -0.998122  -0.181694  2.6758          0  Float64
   8 â”‚ Normal Nucleoli              -1.24677e-16  -0.612478  -0.612478  2.33576         0  Float64
   9 â”‚ Mitoses                       2.17818e-17  -0.348145  -0.348145  4.84614         0  Float64</code></pre><p>Good, now every column has a mean very close to zero, so the standardization was done correctly.</p><p>We now create our model with <code>LeastSquaresSVM</code></p><pre><code class="language-julia">model = LeastSquaresSVM.LSSVClassifier();
</code></pre><p>These are the values for the hyperparameter grid search. We need to find the best subset from this set of parameters. Although I will not do this here, the best approach is to find a set of good hyperparameters and then refine the search space around that set. That way we can ensure we will always get the best results.</p><pre><code class="language-julia">sigma_values = [0.5, 5.0, 10.0, 15.0, 25.0, 50.0, 100.0, 250.0, 500.0];
r1 = MLJBase.range(model, :Ïƒ, values=sigma_values);
gamma_values = [0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0, 500.0, 1000.0];
r2 = MLJBase.range(model, :Î³, values=gamma_values);
</code></pre><p>We now create a <code>TunedModel</code> that will use a 10-folds stratified cross validation scheme in order to find the best set of hyperparameters. The stratification is needed because the classes are somewhat imbalanced:</p><ul><li>Benign: 458 (65.5%)</li><li>Malignant: 241 (34.5%)</li></ul><pre><code class="language-julia">self_tuning_model = TunedModel(
    model=model,
    tuning=Grid(rng=rng),
    resampling=StratifiedCV(nfolds=10),
    range=[r1, r2],
    measure=accuracy,
    acceleration=CPUThreads(), # We use this to enable multithreading
);
</code></pre><p>Once the best model is found, we create a <code>machine</code> with it, and fit it</p><pre><code class="language-julia">mach = machine(self_tuning_model, X, y);
fit!(mach, rows=train, verbosity=0);
</code></pre><p>We can now show the best hyperparameters found.</p><pre><code class="language-julia">fitted_params(mach).best_model</code></pre><pre><code class="language-none">LSSVClassifier(
    kernel = :rbf,
    Î³ = 0.01,
    Ïƒ = 0.5,
    degree = 0)[34m @473[39m</code></pre><p>And we test the trained model. We expect somewhere around 94%-96% accuracy.</p><pre><code class="language-julia">results = predict(mach, rows=test);
acc = accuracy(results, y[test]);
</code></pre><p>Show the accuracy for the testing set</p><pre><code class="language-julia">println(acc * 100.0)</code></pre><pre><code class="language-none">94.73684210526316
</code></pre><p>As you can see, it is fairly easy to use <code>LeastSquaresSVM</code> together with MLJ. We got a good accuracy result and this proves that the implementation is actually correct. This dataset is commonly used as a benchmark dataset to test new algorithms.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">Â« Home</a><a class="docs-footer-nextpage" href="../example2/">Regression on a synthetic dataset Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 25 January 2021 20:49">Monday 25 January 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
